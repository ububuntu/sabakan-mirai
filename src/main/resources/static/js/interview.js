/**
 * WebMéŸ³å£°ã‚’WAVå½¢å¼ã«å¤‰æ›ã™ã‚‹ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚¯ãƒ©ã‚¹
 */
class AudioConverter {
    /**
     * WebM Blobã‚’WAVå½¢å¼ã«å¤‰æ›ï¼ˆ16kHzã«ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼‰
     * @param {Blob} webmBlob WebMå½¢å¼ã®éŸ³å£°Blob
     * @returns {Promise<Blob>} WAVå½¢å¼ã®Blob
     */
    static async convertWebMToWav(webmBlob) {
        try {
            // WebMã‚’ArrayBufferã«å¤‰æ›
            const arrayBuffer = await webmBlob.arrayBuffer();

            // AudioContextã§éŸ³å£°ã‚’ãƒ‡ã‚³ãƒ¼ãƒ‰
            if (!this.audioContext) {
                this.audioContext = new (window.AudioContext || window.webkitAudioContext)();
            }
            const audioBuffer = await this.audioContext.decodeAudioData(arrayBuffer);

            // 16kHzã«ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
            console.log(`ğŸ”„ ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ä¸­: ${audioBuffer.sampleRate}Hz â†’ 16000Hz`);
            const resampled = await this.resampleTo16k(audioBuffer);
            console.log('âœ… ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°å®Œäº†');

            // WAVå½¢å¼ã«å¤‰æ›
            return this.audioBufferToWav(resampled);
        } catch (error) {
            console.error('WAVå¤‰æ›ã‚¨ãƒ©ãƒ¼:', error);
            throw error;
        }
    }

    /**
     * AudioBufferã‚’16kHzã«ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
     * @param {AudioBuffer} audioBuffer å…ƒã®éŸ³å£°ãƒãƒƒãƒ•ã‚¡
     * @returns {Promise<AudioBuffer>} 16kHzã«ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã•ã‚ŒãŸéŸ³å£°ãƒãƒƒãƒ•ã‚¡
     */
    static async resampleTo16k(audioBuffer) {
        const offlineCtx = new OfflineAudioContext(
            audioBuffer.numberOfChannels,
            audioBuffer.duration * 16000,
            16000
        );
        const source = offlineCtx.createBufferSource();
        source.buffer = audioBuffer;
        source.connect(offlineCtx.destination);
        source.start(0);
        return await offlineCtx.startRendering();
    }

    /**
     * AudioBufferã‚’WAVå½¢å¼ã®Blobã«å¤‰æ›
     * @param {AudioBuffer} audioBuffer éŸ³å£°ãƒãƒƒãƒ•ã‚¡
     * @returns {Blob} WAVå½¢å¼ã®Blob
     */
    static audioBufferToWav(audioBuffer) {
        const numberOfChannels = audioBuffer.numberOfChannels;
        const sampleRate = audioBuffer.sampleRate;// PCM
        const bitDepth = 16;

        // ã‚¤ãƒ³ã‚¿ãƒ¼ãƒªãƒ¼ãƒ–å‡¦ç†ï¼ˆã‚¹ãƒ†ãƒ¬ã‚ªã®å ´åˆã€å·¦å³ã®ãƒãƒ£ãƒ³ãƒãƒ«ã‚’äº¤äº’ã«é…ç½®ï¼‰
        const length = audioBuffer.length * numberOfChannels * 2;
        const buffer = new ArrayBuffer(44 + length);
        const view = new DataView(buffer);

        // WAVãƒ˜ãƒƒãƒ€ãƒ¼ã‚’æ›¸ãè¾¼ã¿
        this.writeWavHeader(view, audioBuffer, sampleRate, numberOfChannels, bitDepth);

        // éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’æ›¸ãè¾¼ã¿
        this.writeWavData(view, audioBuffer, numberOfChannels);

        return new Blob([buffer], { type: 'audio/wav' });
    }

    /**
     * WAVãƒ˜ãƒƒãƒ€ãƒ¼ã‚’æ›¸ãè¾¼ã‚€
     */
    static writeWavHeader(view, audioBuffer, sampleRate, numberOfChannels, bitDepth) {
        const blockAlign = numberOfChannels * bitDepth / 8;
        const byteRate = sampleRate * blockAlign;
        const dataSize = audioBuffer.length * blockAlign;

        let offset = 0;

        // "RIFF" ãƒãƒ£ãƒ³ã‚¯
        this.writeString(view, offset, 'RIFF'); offset += 4;
        view.setUint32(offset, 36 + dataSize, true); offset += 4;
        this.writeString(view, offset, 'WAVE'); offset += 4;

        // "fmt " ã‚µãƒ–ãƒãƒ£ãƒ³ã‚¯
        this.writeString(view, offset, 'fmt '); offset += 4;
        view.setUint32(offset, 16, true); offset += 4; // ã‚µãƒ–ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚º
        view.setUint16(offset, 1, true); offset += 2; // ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ (PCM)
        view.setUint16(offset, numberOfChannels, true); offset += 2;
        view.setUint32(offset, sampleRate, true); offset += 4;
        view.setUint32(offset, byteRate, true); offset += 4;
        view.setUint16(offset, blockAlign, true); offset += 2;
        view.setUint16(offset, bitDepth, true); offset += 2;

        // "data" ã‚µãƒ–ãƒãƒ£ãƒ³ã‚¯
        this.writeString(view, offset, 'data'); offset += 4;
        view.setUint32(offset, dataSize, true);
    }

    /**
     * WAVéŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’æ›¸ãè¾¼ã‚€
     */
    static writeWavData(view, audioBuffer, numberOfChannels) {
        const length = audioBuffer.length;
        let offset = 44;

        // ãƒãƒ£ãƒ³ãƒãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        const channels = [];
        for (let i = 0; i < numberOfChannels; i++) {
            channels.push(audioBuffer.getChannelData(i));
        }

        // ã‚¤ãƒ³ã‚¿ãƒ¼ãƒªãƒ¼ãƒ–ã—ãªãŒã‚‰16bitã«å¤‰æ›
        for (let i = 0; i < length; i++) {
            for (let channel = 0; channel < numberOfChannels; channel++) {
                const sample = Math.max(-1, Math.min(1, channels[channel][i]));
                view.setInt16(offset, sample < 0 ? sample * 0x8000 : sample * 0x7FFF, true);
                offset += 2;
            }
        }
    }

    /**
     * DataViewã«æ–‡å­—åˆ—ã‚’æ›¸ãè¾¼ã‚€
     */
    static writeString(view, offset, string) {
        for (let i = 0; i < string.length; i++) {
            view.setUint8(offset + i, string.charCodeAt(i));
        }
    }
}

/**
 * ãƒã‚¤ã‚¯æ©Ÿèƒ½ã‚’ç®¡ç†ã™ã‚‹ã‚¯ãƒ©ã‚¹
 */
class MicrophoneManager {
    constructor(apiBase = '/api') {
        this.apiBase = apiBase;
        this.mediaRecorder = null;
        this.audioChunks = [];
        this.isRecording = false;
        this.recordingInterval = null;
        this.stream = null;
    }

    /**
     * éŒ²éŸ³ã‚’é–‹å§‹ã™ã‚‹
     */
    async start() {
        try {
            this.stream = await navigator.mediaDevices.getUserMedia({
                audio: {
                    echoCancellation: true,
                    noiseSuppression: true,
                    autoGainControl: true
                }
            });

            this.mediaRecorder = new MediaRecorder(this.stream, {
                mimeType: 'audio/webm'
            });

            this.audioChunks = [];

            this.mediaRecorder.ondataavailable = (event) => {
                if (event.data.size > 0) {
                    this.audioChunks.push(event.data);
                }
            };

            this.mediaRecorder.onstop = async () => {
                const audioBlob = new Blob(this.audioChunks, { type: 'audio/webm' });
                await this.sendAudioToServer(audioBlob);
                this.audioChunks = [];
            };

            this.mediaRecorder.start();
            this.isRecording = true;

            this.dispatchEvent('recordingStarted');

            // 5ç§’ã”ã¨ã«éŸ³å£°ã‚’é€ä¿¡
            this.recordingInterval = setInterval(() => {
                if (this.mediaRecorder && this.mediaRecorder.state === 'recording') {
                    this.mediaRecorder.stop();
                    this.mediaRecorder.start();
                }
            }, 5000);

            console.log('ğŸ¤ éŒ²éŸ³ã‚’é–‹å§‹ã—ã¾ã—ãŸ');
            return true;

        } catch (error) {
            console.error('ãƒã‚¤ã‚¯ã‚¢ã‚¯ã‚»ã‚¹ã‚¨ãƒ©ãƒ¼:', error);
            this.dispatchEvent('recordingError', { error: error.message });
            return false;
        }
    }

    /**
     * éŒ²éŸ³ã‚’åœæ­¢ã™ã‚‹
     */
    async stop() {
        try {
            if (this.mediaRecorder && this.mediaRecorder.state !== 'inactive') {
                this.mediaRecorder.stop();
            }

            if (this.stream) {
                this.stream.getTracks().forEach(track => track.stop());
                this.stream = null;
            }

            if (this.recordingInterval) {
                clearInterval(this.recordingInterval);
                this.recordingInterval = null;
            }

            this.isRecording = false;
            this.dispatchEvent('recordingStopped');

            console.log('â¹ï¸ éŒ²éŸ³ã‚’åœæ­¢ã—ã¾ã—ãŸ');
            return true;

        } catch (error) {
            console.error('éŒ²éŸ³åœæ­¢ã‚¨ãƒ©ãƒ¼:', error);
            return false;
        }
    }

    /**
     * éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’WAVå½¢å¼ã«å¤‰æ›ã—ã¦Base64ã§ã‚µãƒ¼ãƒãƒ¼ã«é€ä¿¡
     */
    async sendAudioToServer(audioBlob) {
        return new Promise(async (resolve, reject) => {
            try {
                // WebMã‚’WAVã«å¤‰æ›
                console.log('ğŸ”„ WAVå½¢å¼ã«å¤‰æ›ä¸­...');
                const wavBlob = await AudioConverter.convertWebMToWav(audioBlob);
                console.log('âœ… WAVå¤‰æ›å®Œäº†');

                // Base64ã«å¤‰æ›
                const reader = new FileReader();

                reader.onloadend = async () => {
                    try {
                        const base64Audio = reader.result.split(',')[1];

                        const response = await fetch(`${this.apiBase}/analyze-audio`, {
                            method: 'POST',
                            headers: { 'Content-Type': 'application/json' },
                            body: JSON.stringify({ audio: base64Audio })
                        });

                        const data = await response.json();
                        console.log('âœ… éŸ³å£°é€ä¿¡æˆåŠŸ (WAVå½¢å¼):', data);
                        this.dispatchEvent('audioSent', data);
                        resolve(data);

                    } catch (error) {
                        console.error('âŒ éŸ³å£°é€ä¿¡ã‚¨ãƒ©ãƒ¼:', error);
                        this.dispatchEvent('audioSendError', { error: error.message });
                        reject(error);
                    }
                };

                reader.onerror = () => reject(new Error('ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼'));
                reader.readAsDataURL(wavBlob);

            } catch (error) {
                console.error('âŒ WAVå¤‰æ›ã‚¨ãƒ©ãƒ¼:', error);
                this.dispatchEvent('audioConvertError', { error: error.message });
                reject(error);
            }
        });
    }

    /**
     * ã‚«ã‚¹ã‚¿ãƒ ã‚¤ãƒ™ãƒ³ãƒˆã‚’ç™ºç«
     */
    dispatchEvent(eventName, detail = {}) {
        const event = new CustomEvent(`microphone:${eventName}`, { detail });
        window.dispatchEvent(event);
    }

    /**
     * ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
     */
    cleanup() {
        if (this.isRecording) {
            this.stop();
        }
    }
}

/**
 * AIåˆ†æAPIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
 */
class AnalysisAPIClient {
    constructor(apiBase = '/api') {
        this.apiBase = apiBase;
    }

    async testConnection() {
        const response = await fetch(`${this.apiBase}/test`, { method: 'POST' });
        return await response.json();
    }

    async startAnalysis() {
        const response = await fetch(`${this.apiBase}/start`, { method: 'POST' });
        return await response.json();
    }

    async stopAnalysis() {
        const response = await fetch(`${this.apiBase}/stop`, { method: 'POST' });
        return await response.json();
    }

    async reset() {
        const response = await fetch(`${this.apiBase}/reset`, { method: 'POST' });
        return await response.json();
    }

    async getStatus() {
        const response = await fetch(`${this.apiBase}/status`);
        return await response.json();
    }
}

// ========================================
// ãƒ¡ã‚¤ãƒ³ã®é¢æ¥å‡¦ç†
// ========================================

let microphoneManager;
let apiClient;
let cameraStream;

/**
 * ã‚«ãƒ¡ãƒ©ã¨ãƒã‚¤ã‚¯ã‚’èµ·å‹•
 */
async function startCameraAndMicrophone() {
    try {
        // ã‚«ãƒ¡ãƒ©ã‚’èµ·å‹•
        cameraStream = await navigator.mediaDevices.getUserMedia({
            video: {
                width: { ideal: 1280 },
                height: { ideal: 720 },
                facingMode: "user"
            },
            audio: false
        });

        const videoElement = document.getElementById('input_video');
        if (videoElement) {
            videoElement.srcObject = cameraStream;
            console.log('âœ… ã‚«ãƒ¡ãƒ©ãŒæ­£å¸¸ã«èµ·å‹•ã—ã¾ã—ãŸ');
        }

        // ãƒã‚¤ã‚¯ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã‚’åˆæœŸåŒ–
        microphoneManager = new MicrophoneManager('/api');
        apiClient = new AnalysisAPIClient('/api');

        // ãƒã‚¤ã‚¯ã‚’è‡ªå‹•çš„ã«é–‹å§‹
        const micStarted = await microphoneManager.start();
        if (micStarted) {
            updateMicStatus('éŒ²éŸ³ä¸­', '#dc3545');
        } else {
            console.warn('âš ï¸ ãƒã‚¤ã‚¯ã®èµ·å‹•ã«å¤±æ•—ã—ã¾ã—ãŸ');
            updateMicStatus('ã‚¨ãƒ©ãƒ¼', '#dc3545');
        }

        // åˆ†æã‚’é–‹å§‹
        const result = await apiClient.startAnalysis();
        console.log('âœ… åˆ†æé–‹å§‹:', result);

    } catch (error) {
        console.error('âŒ èµ·å‹•ã‚¨ãƒ©ãƒ¼:', error);
        updateMicStatus('ãƒã‚¤ã‚¯ã‚¨ãƒ©ãƒ¼', '#dc3545');
    }
}

/**
 * ãƒã‚¤ã‚¯ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹è¡¨ç¤ºã‚’æ›´æ–°
 */
function updateMicStatus(text, color) {
    const micStatus = document.getElementById('micStatus');
    if (micStatus) {
        micStatus.textContent = `ğŸ¤ ãƒã‚¤ã‚¯: ${text}`;
        micStatus.style.color = color;
    }
}

/**
 * ãƒã‚¤ã‚¯ã‚¤ãƒ™ãƒ³ãƒˆãƒªã‚¹ãƒŠãƒ¼ã‚’è¨­å®š
 */
function setupMicrophoneEvents() {
    window.addEventListener('microphone:recordingStarted', () => {
        updateMicStatus('éŒ²éŸ³ä¸­', '#dc3545');
        console.log('ğŸ¤ éŒ²éŸ³é–‹å§‹');
    });

    window.addEventListener('microphone:recordingStopped', () => {
        updateMicStatus('åœæ­¢ä¸­', '#666');
        console.log('â¹ï¸ éŒ²éŸ³åœæ­¢');
    });

    window.addEventListener('microphone:audioSent', (e) => {
        console.log('ğŸ“¤ éŸ³å£°ãƒ‡ãƒ¼ã‚¿é€ä¿¡å®Œäº†:', e.detail);
    });

    window.addEventListener('microphone:recordingError', (e) => {
        console.error('âŒ éŒ²éŸ³ã‚¨ãƒ©ãƒ¼:', e.detail.error);
        updateMicStatus('ã‚¨ãƒ©ãƒ¼', '#dc3545');
    });

    window.addEventListener('microphone:audioSendError', (e) => {
        console.error('âŒ éŸ³å£°é€ä¿¡ã‚¨ãƒ©ãƒ¼:', e.detail.error);
    });

    window.addEventListener('microphone:audioConvertError', (e) => {
        console.error('âŒ WAVå¤‰æ›ã‚¨ãƒ©ãƒ¼:', e.detail.error);
    });
}

/**
 * é¢æ¥åœæ­¢å‡¦ç†
 */
async function stopInterview() {
    try {
        // ãƒã‚¤ã‚¯ã‚’åœæ­¢
        if (microphoneManager && microphoneManager.isRecording) {
            await microphoneManager.stop();
        }

        // ã‚«ãƒ¡ãƒ©ã‚’åœæ­¢
        if (cameraStream) {
            cameraStream.getTracks().forEach(track => track.stop());
            cameraStream = null;
        }

        // åˆ†æã‚’åœæ­¢
        if (apiClient) {
            const result = await apiClient.stopAnalysis();
            console.log('åˆ†æçµæœ:', result);
        }

        console.log('âœ… é¢æ¥ã‚’æ­£å¸¸ã«åœæ­¢ã—ã¾ã—ãŸ');

        // çµæœãƒšãƒ¼ã‚¸ã¸é·ç§»
        location.href = './interview-result';

    } catch (error) {
        console.error('âŒ åœæ­¢å‡¦ç†ã‚¨ãƒ©ãƒ¼:', error);
        location.href = './interview-result';
    }
}

/**
 * ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å‡¦ç†
 */
function cleanup() {
    try {
        // ã‚«ãƒ¡ãƒ©ã‚’åœæ­¢
        if (cameraStream) {
            cameraStream.getTracks().forEach(track => {
                if (track.readyState !== 'ended') {
                    track.stop();
                }
            });
            cameraStream = null;
        }

        // ãƒã‚¤ã‚¯ã‚’åœæ­¢
        if (microphoneManager && microphoneManager.isRecording) {
            microphoneManager.cleanup();
        }

        console.log('âœ… ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†');
    } catch (error) {
        console.error('ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼:', error);
    }
}

// ========================================
// ã‚¤ãƒ™ãƒ³ãƒˆãƒªã‚¹ãƒŠãƒ¼
// ========================================

// ãƒšãƒ¼ã‚¸èª­ã¿è¾¼ã¿æ™‚ã®åˆæœŸåŒ–
window.addEventListener('DOMContentLoaded', async () => {
    setupMicrophoneEvents();
    await startCameraAndMicrophone();
});

// ãƒšãƒ¼ã‚¸ã‚’é›¢ã‚Œã‚‹æ™‚ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
window.addEventListener('beforeunload', () => {
    cleanup();
});